# Tutorial on running a Graded Response Model, initiated on 09.11.2023
# by Rizqy Amelia Zein and Hanif Akhtar
# LMU Munich, Universitas Airlangga (UNAIR), ELTE Eötvös Loránd University, and Universitas Muhammadiyah Malang (UMM)


# Welcome to the tutorial!  ------
# This tutorial aims to familiarize applied psychological researchers to item response theory (IRT) modeling, 
# or more specifically, a graded response model (GRM). GRM is a part of IRT family, specifically designed for
# examining the performance of a scale with polytomous responses (Likert-type scale).

# To this end, we will show you how to run a GRM, using data from the Open Psychometric Database, specifically 
# the right-wing authoritarianism (RWA) scale (Altemeyer). 


## Step 1: Install and activate the packages ##  ------

# First of all, we should install the packages we need for the analysis. If you already have these packages  
# already installed in your device, you can safely skip this step.

# install.packages("tidyverse", "psych", "devtools", "mirt", "caret", dependencies=TRUE) 
## INFO: Remove the hashtag before install.package() to start installing packages (only if you have not had them installed) ##

# package `ggmirt` is not available in CRAN, so we have to do a remote installation by downloading the package from its Github repository.

devtools::install_github("masurp/ggmirt")

# Now, we activate the package:

library(tidyverse); library(psych); library(mirt); library(ggmirt); library(caret)

## Step 2: Downloading, storing, and preparing the data for analysis ##   ------

# Before running our analysis, of course we should download our dataset first. Here, we have written codes to automatically
# download the file from the Open Psychometric database. You can always adjust these codes according to your needs.

url <- "https://openpsychometrics.org/_rawdata/RWAS.zip" # Defining the URL of the zip file

# If you look closely at the .zip folder, there are two files in there; one is a .csv file (this is the dataset),
# and two, a .txt file (a codebook). Since we need them both, we will extract them and make them readable in R environment.

zip_file_path <- tempfile(fileext = ".zip") # Defining the path to temporarily save the downloaded zip file
download.file(url, zip_file_path, mode = "wb") # Downloading the zip file
extracted_files_path <- tempdir() # Defining the path to extract the contents of the zip file
unzip(zip_file_path, exdir = extracted_files_path) # Unzipping the .zip file
files <- list.files(extracted_files_path, recursive = TRUE, full.names = TRUE) # List all the files in the extracted directory, including subdirectories

csv_files <- grep("\\.csv$", files, value = TRUE) # Filtering for .csv files
txt_files <- grep("\\.txt$", files, value = TRUE) # Filtering for .txt files


if (length(csv_files) == 0) {
  stop("No .csv files found in the zip archive.")
} # now checking if there are any .csv files, and if that's the case, the script gives no error message

if (length(txt_files) == 0) {
  stop("No .txt files found in the zip archive.")
} # do the same thing for .txt file

ds <- read.csv(csv_files[1]) # Read the .csv file into a data frame
codebook <- readLines(txt_files[1]) # Read the .txt file into R

unlink(zip_file_path)
unlink(extracted_files_path, recursive = TRUE)
rm(csv_files, txt_files, extracted_files_path, files, url, zip_file_path)
# This three lines of script are used to clean up the temporary files and values remaining in the R environment

str(ds) # Now we are checking the structure of data frame "ds", which contains our data so that we can work with it!
# By looking at the structure, it's very likely that columns "Q1-Q22" are RWA items, because RWA consists of 22 items.
# but let's check the codebook just to make sure...

print(codebook) # If we look at the codebook, columns "Q1-Q22" indeed are the RWA data (see line 5-7), so our next step
# is to create a new data frame that contains only RWA items because this what we are interested in.
rm(codebook) # now we delete the codebook since we no longer need it.

rwa <- subset(ds, select = Q1:Q22) # now we subset our data because we are only interested in RWA items.
# After executing this line of code above, we shall see in the R environment that we have a new data frame, namely "rwa"
# which contains of 22 columns (variable) and 9881 data points (participants).

# Now let's check the structure of our new data frame containing only RWA items.
str(rwa)

## Step 3: Inspecting key descriptive statistics ##   ------

# This part is fairly straightforward. Before performing analysis, it is very important to explore
# key descriptive statistics of the data. We are using a neat function in `psych` package: (`describe()`)

psych::describe(rwa)
# As we see here in the console, mean score of the items differ - some items have small mean scores (~2-3), while the
# others are quite large (~6-7). The reason for this is that the RWA scale has unfavorable items 
# so to simplify the interpretation, we should reverse their scores.

# Unfavorable items are Q4, Q6, Q8, Q9, Q11, Q13, Q15, Q18, Q20, and Q21

unfav <- c("Q4","Q6","Q8","Q9","Q11","Q13","Q15","Q18","Q20","Q21") # Now we create a vector defining which items will be coded reversely.
rwa <- rwa %>% 
  mutate(across(all_of(unfav), ~ 9 - .))# We simply subtract the scores from 9 (the maximum) to reverse code the unfavorable items.
rm(unfav) # We don't need the vector, so we remove it now to keep our workspace clean.

# Let's see if the items are coded in the same direction now.
psych::describe(rwa)
# Yes, the items are coded on the same direction, but why there are "0" values in all columns (see column "min")?
# The items are not supposed to have "0" value because the responses are ranging from 1-9.

# Let's count how many "0" we have in our data.

zero <- colSums(rwa == 0) / nrow(rwa) # Counting the frequency of "0" in each column.
print(zero) # The proportion of "0" for each item.

# We have a significant proportion of "0" in several items (Q4, Q6, Q9, Q11, and Q18). 
# There is no explanation what "0" means, but it is very possible that "0" is used to code a missing response.
# It is actually still possible to run an IRT analysis with missing data, but we have to ensure that the data are missing
# at random (MAR). However, with the proportion of missing responses even exceeding 60% for some items,
# we don't think it's plausible to assume MAR. One solution for this is simply exclude all cases with missing responses.
# Let's assume then that "0" means missing response, and then delete all cases with missing responses.

rwa <- rwa %>%
  mutate_all(~na_if(., 0)) %>%  # Replace 0 with NA in all columns.
  drop_na()  # Remove rows with any NA values.
rm(zero)

# Then let's check our data again.
psych::describe(rwa)

# Apparently now all items are on the same direction, but we lost more 80% of our sample. It's also important to note that
# no participants scored "9" in item 6 and 18. This is not a problem at all, but we have to be aware of this situation.
# This is indeed a downside of our decision deleting all the cases with missing responses, but we since it is 
# unclear what "0" means (it is safer to assume that it a code for missing responses) and we still 
# have a sizeable sample (>1000), let's proceed to the next step! 

## Step 4: Examining dimensionality ##  ------

# While now it is computationally possible to run a multidimensional IRT analysis, in general, an IRT model assumes
# that the items are locally independent. 
# Bob Altemeyer (1996) argues in his book that while the RWA scale consists of three sub-dimensions,
# which are submissiveness, aggression, and conventionalism, the RWA scale is essentially unidimensional because these 
# three sub-dimensions are strongly intercorrelated.
# Therefore, we may assume that the scale is supposed to be unidimensional. 

# To check the unidimensionality of the RWA scale, we can implement two approaches:
# First, we can run an exploratory factor analysis (EFA) using a polychoric correlation matrix. This approach is generally
# recommended if we have a Likert scale with 4-7 possible responses. This can be neatly done using a simple script (`psych`) 
# below:

irt.fa(rwa, nfactors = 1, fm = "minres")

# Alternatively, we can run a parallel analysis also with a polychoric correlation matrix. This approach
# is, in general, better than EFA because a parallel analysis compares Eigenvalues (a scalar which measures the amount
# of variance that is accounted for by each latent factor) from a set of simulated data.
# Again, to perform this, we need to run a simple command:

fa.parallel(rwa, nfactors = 1, fm="minres", fa="fa", cor = "poly")

# However, as we see in the console, there is an error message which tells us that R stopped the analysis.
# This is because performing parallel analysis or EFA using a polychoric correlation matrix is not needed when we have
# more than 8 categories (responses) in our scale. This means we can treat our data as continuous (instead of ordinal). 
# The RWA scale has nine responses so let's do EFA and parallel analysis using a pearson correlation matrix instead.

cor <- cor(rwa,method="pearson", use="pairwise.complete.obs") # First, creating cor matrix.
efa <- fa(rwa, nfactors=1, fm="minres") # Now, running exploratory factor analysis.
print(efa) # Print the results.

# Let's look at the output. MR1 reflects factor loadings of each item. As we see, all items are strongly loaded to 
# the single factor. The rule of thumb is 0.3, and we can see here all the loadings are more than 0.3.
# We also see that the proportion of total variance that is explained by the factor (see "Proportion Var") shows 0.55,
# this means that the factor accounts for a significant portion (55%) of the variance of the data.
# In general, our assumption regarding the unidimensionality of the RWA scale holds, but to paint a clearer picture, 
# let's see the scree plot.

plot(efa$values, type = "b", main = "Scree Plot", xlab = "Factor", ylab = "Eigenvalue") 
abline(h = 1, col = "red", lty = 2)

# As we see in the plot, the Eigenvalue significantly levels off after one factor, which further substantiates our assumption.
# However, let's run a parallel analysis, since this approach is better than running EFA.

pa <- fa.parallel(rwa, fm="minres", fa="fa")

# Again, from the plot, we can conclude that one latent factor is sufficient, further substantiates our assumption.

## Step 5: Model estimation, parameters, and fit statistics ##  ------

# Now we have evidence that the scale is unidimensional, now it is the time to estimate our model.
# As the first step, let's define our model:

model <- 'rwa = 1-22' # This script means that our model consists of a latent factor namely "rwa"
# and consists of 22 items (column 1 to column 22).

# Now, we estimate our model...
fit <- mirt(data=rwa, 1, model=model, itemtype="graded", SE=T, verbose=F) # This script means we're testing 
# the RWA scale as a unidimensional construct 

# ...and store the model parameters in a data frame.
coefs <- coef(fit, IRTpars=T, printSE=T) 

# Let's take a look at the model parameters!
print(coefs)

summary(fit)
itemfit(fit) 

M2(fit, type="C2") 

## Step 6: Testing local independence assumption (again) using different strategies (local dependency statistics) ##  ------

q3 <- residuals(fit, type = "Q3")
findCorrelation(q3, cutoff = 0.2, verbose = T) # Q4, Q5, Q6, Q7, Q11, Q13, Q14, Q15, Q18, Q19, Q21, Q22 are problematic.

ld <- residuals(fit, type = "LD")
upper_diag_indices <- which(upper.tri(ld), arr.ind = T)
large_values_indices <- upper_diag_indices[ld[upper_diag_indices] > 0.2 | ld[upper_diag_indices] < -0.2, ]

for (i in 1:nrow(large_values_indices)) {
  row <- large_values_indices[i, 1]
  col <- large_values_indices[i, 2]
  value <- ld[row, col]
  cat(sprintf("A large correlation is found at [%d, %d]: %f\n", row, col, value))
} # Q3, Q7, Q9, Q10, Q11, Q12, Q13, Q14, Q15, Q17, Q19, Q21, Q22 are seemingly problematic here.



## Step 7: Plots (category probability function, item information function, and test information function) ##   ------

tracePlot(fit, title = "Category Probability Function of RWA Scale")

itemInfoPlot(fit, facet=T, title = "Item Information Curves of the RWA Scale")

testInfoPlot(fit, title="Test Information Curve of the RWA Scale")

scaleCharPlot(fit, title="Scale Characteristic Curve of the RWA Scale")

## Step 8: Extracting factor scores (theta) ##   ------

theta_se <- fscores(fit, full.scores.SE = T)

## Step 9: Estimating reliability ##   ------

marginal_rxx(fit)
conRelPlot(fit, title="Reliability of the RWA Scale Given to the θ Level")
empirical_rxx(theta_se)

alpha(rwa)
omega(rwa)


# Session Info ------
sessionInfo()